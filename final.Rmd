---
title: "final_recovery_time"
output:
  pdf_document: default
  html_document: default
date: "2023-05-10"
---

```{r setup, include=FALSE}
library(ggplot2)
library(glmnet)
library(MASS)
library(tidyverse)
library(cowplot)
library(corrgram)
library(dplyr)
library(caret)
library(reshape2)
library(plyr)
library(corrplot)
library(rpart)
library(rpart.plot)
library(readr)
library(ranger)
```

Data Cleaning
```{r}
dat0 = read_csv(file = "final_used_data.csv")
dat1 <- na.omit(dat0)

#Create a new data frame without id variable
dat <- dat1[ , !names(dat0) %in% c("id")]
attach(dat)

```

Data Preprocessing
```{r}
#Visualize response variable
par(mfrow = c(1, 2))
boxplot(dat$recovery_time, main = "COVID-19 Recovery Time")
hist(dat$recovery_time, main = "Distribution of Rescovery Time", col = "lightblue",
                        xlab = "Recovery Time", prob = TRUE, ylim = c(0,0.03))
lines(density(dat$recovery_time))
abline(v = mean(dat$recovery_time), lty = "dashed", col = "red")
# The above plots show that the response variable is right-skewed, so log-transformation was performed. 


dat$log_recovery_time <- log(dat$recovery_time)
par(mfrow = c(1, 2))
boxplot(dat$log_recovery_time, main = "COVID-19 Recovery Time")
hist(dat$log_recovery_time, main = "Distribution of Rescovery Time", col = "lightblue",
xlab = "Log Recovery Time", prob = TRUE, ylim = c(0,1))
lines(density(dat$log_recovery_time))
abline(v = mean(dat$log_recovery_time), lty = "dashed", col = "red")
#After the transformation, the outcome variable is normally distributed.
```

Data Partition
```{r }
set.seed(5220)
trainRows <- createDataPartition(y = dat$log_recovery_time, p = 0.8, list = FALSE)

# Training data
dat_train = dat[trainRows, ]
x_train = model.matrix(log_recovery_time~.,dat)[trainRows, -1]
y_train = dat$log_recovery_time[trainRows]
# Test data
dat_test = dat[-trainRows, ]
x_test = model.matrix(log_recovery_time~.,dat)[-trainRows, -1]
y_test = dat$log_recovery_time[-trainRows]

```

Exploratory Analysis & Data Visualization
```{r}
# Summary statistics for each variable
summary(dat_train)

#Relocate columns putting non-discrete predictors together
dat1 =
  dat %>% 
  select(age,bmi,sbp,ldl,recovery_time)


# Correlation Plot
dat2 <- model.matrix(log_recovery_time ~ ., dat1)[ ,-1]
x <- dat2[trainRows,]
corrplot(cor(x))


# Convert non-numeric columns to numeric
dat_train1 <- dat_train
non_numeric_cols <- sapply(dat_train1, function(x) !is.numeric(x))
dat_train1[, non_numeric_cols] <- lapply(dat_train1[, non_numeric_cols], as.numeric)


```
Fit LASSO
```{r}
ctrl1 <- trainControl(method = "repeatedcv", number = 10, repeats = 5)

set.seed(5220)
lasso.fit <- train(x_train, y_train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1,
                                          lambda = exp(seq(5, -1, length=100))),
                   trControl = ctrl1)
plot(lasso.fit, xTrans = log)

lasso.fit$bestTune
coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)

```


Fit Elastic net
```{r}
set.seed(5220)
enet.fit <- train(x_train, y_train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                  lambda = exp(seq(2, -2, length = 50))),
                  trControl = ctrl1)
enet.fit$bestTune

coef(enet.fit$finalModel, enet.fit$bestTune$lambda)

plot(enet.fit)
```


Fit PCR
```{r}
ctrl2 <- trainControl(method = "repeatedcv",
                      number = 10,
                      repeats = 5,
                      selectionFunction = "best")

set.seed(5220)
pcr.fit <- train(x_train, y_train,
                 method = "pcr",
                 tuneGrid = data.frame(ncomp = 1:13),
                 trControl = ctrl2,
                 preProcess = c("center", "scale"))

ggplot(pcr.fit, highlight = TRUE) + theme_bw()
summary(pcr.fit)
```


Fit PLS
```{r}
set.seed(5220)
pls.fit <- train(x_train, y_train,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:13),
                 trControl = ctrl2,
                 preProcess = c("center", "scale"))

ggplot(pls.fit, highlight = TRUE)

summary(pls.fit)
```


Fit GAM
```{r}
#ctrl3 <- trainControl(method = "cv", number = 10)

set.seed(5220)
gam.fit <- train(x_train, y_train,
                 method = "gam",
                 trControl = ctrl1)
gam.fit$bestTune

gam.fit$finalModel

coef(gam.fit$finalModel)


mod_gam <- gam(log_recovery_time ~ gender + race + smoking + hypertension + 
    diabetes + vaccine + severity + s(age) + 
    s(sbp) + s(ldl) + s(bmi),
               data = dat[trainRows,], method = "REML")

summary(mod_gam)


par(mfrow = c(1,6)) 
plot(gam.fit$finalModel)


```


Fit MARS
```{r}
mars_grid <- expand.grid(degree = 1:3,
                         nprune = 2:15)
set.seed(5220)
mars.fit <- train(x_train, y_train,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl1)
ggplot(mars.fit)

mars.fit$bestTune

coef(mars.fit$finalModel)
```

```{r, include = FALSE,  warning=FALSE}
library(tidyverse)
library(knitr)
library(caret)
library(rpart.plot)
library(randomForest)
library(ranger)
library(gbm)
library(ISLR) 
library(visdat)

# general setting for plots and themes
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.align = "center", cache = TRUE, 
                      fig.width = 6, fig.asp = 0.6, out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Data preparation

```{r, include=FALSE}
covid = read.csv("final_used_data.csv") %>% 
  mutate(
    gender = as.factor(gender),
    race = as.factor(race),
    smoking = as.factor(smoking),
    hypertension = as.factor(hypertension),
    diabetes = as.factor(diabetes),
    vaccine = as.factor(vaccine),
    severity = as.factor(severity)) %>%
select(-id)
# no missing data found
vis_miss(covid)
```

### Data partition

Next, we split the dataset into two parts: training data (80%) and test data (20%).

```{r split}
set.seed(2266)
trainRows <- createDataPartition(y = covid$recovery_time, p = 0.8, list = FALSE)

# Training data
covid_train = covid[trainRows, ]
x_train = model.matrix(recovery_time~.,covid)[trainRows, -1]
y_train = covid$recovery_time[trainRows]
# Test data
covid_test = covid[-trainRows, ]
x_test = model.matrix(recovery_time~.,covid)[-trainRows, -1]
y_test = covid$recovery_time[-trainRows]

# create cross-validation objects
ctrl1 <- trainControl(method = "cv")
```

## (a) Regression tree

Build a regression tree on the training data to predict the response. Create a plot of the tree.

```{r}
set.seed(2266)

# build a regression tree on the training data
rpart.fit <- train(recovery_time ~ . ,
                   data = covid_train,
                   method = "rpart", 
                   tuneGrid = data.frame(cp = exp(seq(-6,-2, length = 50))),
                   trControl = ctrl1)
rpart.fit$bestTune
# plot of the complexity parameter
ggplot(rpart.fit, highlight = TRUE) 

# importance
plot(varImp(rpart.fit, scale = TRUE))

# create a plot of the tree
rpart.plot(rpart.fit$finalModel)
```

- The root node is `bmi` over or under 34. 
- The optimal cp is 0.002918356.
- The pruned tree based on the optimal cp value is plotted as above. It's quite complicated with 15 terminal nodes and 14 splits.
- The model indicated that the variables `bmi` has the highest predictive power, followed by `vaccine1`, `age`, and `sbp`.


## (b) Random forest

Perform random forest on the training data. Report the variable importance and 
the test error.

```{r}
rf.grid <- expand.grid(mtry = 1:11,
                       splitrule = "variance",
                       min.node.size = 1:6)

set.seed(2266)
# train a random forest model on the training data
rf.fit <- train(recovery_time ~ .,
               data = covid_train,
                method = "ranger",
                tuneGrid = rf.grid,
                trControl = ctrl1)

ggplot(rf.fit, highlight = TRUE)
rf.fit$bestTune
```

- Using ranger method, we perform Random Forest algorithm with minimum node size 6 and 4 selected predictors.

- It is a common practice to investigate the variables with the greatest predictive power once a random forest model has been trained. These important variables play a crucial role in determining the outcome, and their values can have a substantial impact on the results. Conversely, variables with low importance may be omitted from the model, leading to a streamlined model that is more efficient in terms of fitting and prediction accuracy.

```{r, warning=FALSE}
# variable importance using permutation methods 
set.seed(2266)
rf.perm = ranger(recovery_time ~ ., 
                      data = covid_train,
                      mtry = rf.fit$bestTune[[1]],
                      splitrule = "variance",
                      min.node.size = rf.fit$bestTune[[3]],
                      importance = "permutation",
                      scale.permutation.importance = TRUE)
# report variable importance
barplot(sort(ranger::importance(rf.perm), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7, 
        col = colorRampPalette(colors = c("cyan", "blue"))(19))

# variable importance using impurity methods
set.seed(2266)
rf.impu <- ranger(recovery_time ~ .,
                        data = covid_train,
                        mtry = rf.fit$bestTune[[1]],
                        splitrule = "variance",
                        min.node.size = rf.fit$bestTune[[3]],
                        importance = "impurity")
# report variable importance
barplot(sort(ranger::importance(rf.impu), decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan", "blue"))(19))
```

- Calculate and graph variable importance using permutation and impurity metrics.

- The model using impurity method indicated that the variables `bmi` has the highest predictive power, followed by `ldl`, `sbp`, and `age`. Their values were the most significant in determining `recovery_time`. This suggests that these variables play a crucial role in influencing the Covid recovery time. Moreover, vaccinated status, race and smoking or not also contributes to the outcome. 

- Similarly, The model using permutation method indicated that the variables `bmi` has the highest predictive power, followed by `vaccine`, `gender` , `severity`, `hypertension` and `sbp`. 


```{r, warning=FALSE}
# test error
pred.rf <- predict(rf.fit, newdata = covid_test)
RMSE(pred.rf, covid_test$recovery_time)
```

- The test error of the model is 25.54926

## (c) Boosting

Perform boosting on the training data. Report the variable importance and the test
error.

```{r, warning=FALSE}
# train model using gbm with grid of tuning parameters
bst.grid = expand.grid(n.trees = c(2000,3000,4000,5000),
                        interaction.depth = 1:3,
                        shrinkage = c(0.005,0.01),
                        n.minobsinnode = c(1))

set.seed(2266)
bst.fit <- train(recovery_time ~.,
                 data = covid_train,
                 method = "gbm",
                 tuneGrid = bst.grid,
                 trControl = ctrl1,
                 verbose = FALSE)

ggplot(bst.fit, highlight = TRUE)
bst.fit$bestTune
```

We use the gradient boosting method implemented with gbm in caret package.

```{r, warning=FALSE}
# variable importance
summary(bst.fit$finalModel, las = 2, cBars = 11, cex.names = 0.6)

# test error
pred.bst <- predict(bst.fit, newdata = covid_test)
RMSE(pred.bst, covid_test$recovery_time)

```

- The most important variables for gradient boosting are still `bmi`. Other important variables include `ldl`, `sbp`  and `age`. 

- The test error for boosting is 25.13826,  smaller than the test error for random forest.



Model Comparison
```{r}
set.seed(5220)
resamp <- resamples(list(enet = enet.fit, lasso = lasso.fit, pcr = pcr.fit, pls = pls.fit, gam=gam.fit))
summary(resamp)

bwplot(resamp, metric = "RMSE")
```

Regression tree
```{r}
set.seed(5220)

rpart.fit <- train(recovery_time ~ . ,
                   data = dat_train,
                   method = "rpart", 
                   tuneGrid = data.frame(cp = exp(seq(-6,-2, length = 50))),
                   trControl = ctrl1)
rpart.fit$bestTune
# Plot of the complexity parameter
ggplot(rpart.fit, highlight = TRUE) 

# Variable importance
plot(varImp(rpart.fit, scale = TRUE))

rpart.plot(rpart.fit$finalModel)

pred.rf <- predict(rpart.fit, newdata = dat_test)
RMSE(pred.rf, dat_test$recovery_time)
```

Random forest
```{r}
rf.grid <- expand.grid(mtry = 1:11,
                       splitrule = "variance",
                       min.node.size = 1:6)

set.seed(5220)

rf.fit <- train(recovery_time ~ .,
               data = dat_train,
                method = "ranger",
                tuneGrid = rf.grid,
                trControl = ctrl1)

ggplot(rf.fit, highlight = TRUE)
rf.fit$bestTune
```



```{r, warning=FALSE}
# variable importance using permutation methods 
set.seed(5220)
rf.perm = ranger(recovery_time ~ ., 
                      data = dat_train,
                      mtry = rf.fit$bestTune[[1]],
                      splitrule = "variance",
                      min.node.size = rf.fit$bestTune[[3]],
                      importance = "permutation",
                      scale.permutation.importance = TRUE)

barplot(sort(ranger::importance(rf.perm), decreasing = FALSE), 
        las = 2, horiz = TRUE, cex.names = 0.7, 
        col = colorRampPalette(colors = c("cyan", "blue"))(19))

# variable importance using impurity methods
set.seed(5220)
rf.impu <- ranger(recovery_time ~ .,
                        data = dat_train,
                        mtry = rf.fit$bestTune[[1]],
                        splitrule = "variance",
                        min.node.size = rf.fit$bestTune[[3]],
                        importance = "impurity")

barplot(sort(ranger::importance(rf.impu), decreasing = FALSE),
        las = 2, horiz = TRUE, cex.names = 0.7,
        col = colorRampPalette(colors = c("cyan", "blue"))(19))
```


```{r, warning=FALSE}
# test error
pred.rf <- predict(rf.fit, newdata = dat_test)
RMSE(pred.rf, dat_test$recovery_time)
```

Boosting
```{r, warning=FALSE}
bst.grid = expand.grid(n.trees = c(2000,3000,4000,5000),
                        interaction.depth = 1:3,
                        shrinkage = c(0.005,0.01),
                        n.minobsinnode = c(1))

set.seed(5220)
bst.fit <- train(recovery_time ~.,
                 data = dat_train,
                 method = "gbm",
                 tuneGrid = bst.grid,
                 trControl = ctrl1,
                 verbose = FALSE)

ggplot(bst.fit, highlight = TRUE)
bst.fit$bestTune
```


```{r, warning=FALSE}
# variable importance
summary(bst.fit$finalModel, las = 2, cBars = 11, cex.names = 0.6)

# test error
pred.bst <- predict(bst.fit, newdata = dat_test)
RMSE(pred.bst, dat_test$recovery_time)

```

Model Comparison
```{r}
set.seed(5220)
resamp <- resamples(list(enet = enet.fit, lasso = lasso.fit, pcr = pcr.fit, pls = pls.fit, gam=gam.fit, tree=rpart.fit, rf=rf.fit, boosting=bst.fit))
summary(resamp)

bwplot(resamp, metric = "RMSE")
```

secondar analysis


```{r}

library(summarytools)
library(glmnet)
library(caret)
library(corrplot)

library(ISLR)
library(plotmo)

library(caret)
library(glmnet)
library(mlbench)
library(pROC)
library(pdp)
library(rpart)
library(rpart.plot)
library(gbm)
library(tree)
library(caret)
library(party)
library(ranger)
library(randomForest)

library(e1071)
```
1. Impotant data and treat recovery time as binary
```{r setup, include=FALSE}

data = read.csv("final_used_data.csv")
#qing_zhou_data = read.csv("Qing Zhou_data_id.csv")
#data <- subset(data, select = -c(height, weight, study))
#names(data) <- tolower(names(data))
#write.csv(unique_merged_data, "final_used_data.csv", row.names = FALSE)
#merged_data <- rbind(data, qing_zhou_data)
#unique_merged_data <- unique(merged_data)
data$binary_recovery <- ifelse(data$recovery_time > 30, 1, 0)
table(data$binary_recovery)
```
2. produce the training set
```{r cars}
set.seed(2023)
rowTrain <- createDataPartition(y = data$recovery_time,
p = 0.8,
list = FALSE)
data$binary_recovery <- factor(data$binary_recovery)
contrasts(data$binary_recovery)
dat = data[, -1]
dat$binary_recovery <- factor(dat$binary_recovery)
```

3.condcut regression
Therer are no significant p value, indicating the logistic regression is not a suitable model for the secondary analysis
```{r}
glm.fit <- glm(binary_recovery ~ .,
              data = dat[rowTrain, ],
              subset = rowTrain,
              family = binomial(link = "logit"))
summary(glm.fit)
```
4. roc curve
```{r}
test.pred.prob <- predict(glm.fit, newdata = dat[-rowTrain,],
                type = "response")
                test.pred <- rep("0", length(test.pred.prob))
                test.pred[test.pred.prob>0.5] <- "1"
                confusionMatrix(data = as.factor(test.pred),
                reference = dat$binary_recovery[-rowTrain],
                positive = "1")
test.pred <- ifelse(test.pred.prob > 0.5, 1, 0)
confusionMatrix(data = as.factor(test.pred),
                reference = dat$binary_recovery[-rowTrain],
                positive = "1")
roc.glm <- roc(dat$binary_recovery[-rowTrain], test.pred.prob)
plot(roc.glm, legacy.axes = TRUE, print.auc = TRUE)
#plot(smooth(roc.glm), col = 4, add = TRUE)


```


5. classification tree
rpart
```{r}
tree1 <- rpart(formula = binary_recovery ~ . ,
data = dat,
subset = rowTrain,
control = rpart.control(cp = 0))
cpTable <- printcp(tree1)
plotcp(tree1)
minErr <- which.min(cpTable[,4])
tree2 <- prune(tree1, cp = cpTable[minErr,1])
rpart.plot(tree2)
summary(tree2)

#cross validation
folds <- createFolds(dat$binary_recovery, k = 10)
ctrl <- trainControl(method = "cv", 
                     index = folds,
                     savePredictions = TRUE,
                     classProbs = TRUE)

levels(dat$binary_recovery) <- make.names(levels(dat$binary_recovery))
model <- train(binary_recovery ~ ., 
               data = dat, 
               method = "rpart", 
               trControl = ctrl)

ggplot(model, highlight = TRUE) 
print(model)

rpart.fit <- train(recovery_time ~ . ,
                   data = dat,
                   method = "rpart", 
                   tuneGrid = data.frame(cp = exp(seq(-6,-2, length = 50))),
                   trControl = ctrl1)
rpart.fit$bestTune
rpart.plot(rpart.fit$finalModel)
```
Based on the output, the classification tree model was trained using cross-validation on a dataset with 2000 samples and 15 predictors. The model was evaluated using accuracy and kappa metrics and optimized using the largest accuracy value. The optimal model had a complexity parameter (cp) value of 0.5, which resulted in an accuracy of 0.997 and kappa of 0.994. This suggests that the model performs very well in predicting the binary_recovery outcome variable, and the chosen cp value effectively balances the bias-variance tradeoff in the model.


6. random forest

```{r}
dat = data[, -1]
set.seed(1)
bagging <- randomForest(binary_recovery ~ . ,
dat[rowTrain,],
mtry = 8)
set.seed(1)
rf <- randomForest(binary_recovery ~ . ,
                    dat[rowTrain,],
                    mtry = 3)
                    set.seed(1)
                    rf2 <- ranger(binary_recovery ~ . ,
                    dat[rowTrain,],
                    mtry = 3,
                    probability = TRUE)

rf.pred <- predict(rf, dat[-rowTrain,])
confusionMatrix(data=rf.pred, reference=dat[-rowTrain,]$binary_recovery, positive="1")

#summary(dat)
rf.grid <- expand.grid(mtry = 1:11,
splitrule = "variance",
 min.node.size = 1:6)
set.seed(2266)
ctrl1 <- trainControl(method = "cv")
# train a random forest model on the training data
rf.fit <- train(recovery_time ~ .,
               data = dat,
                method = "ranger",
                tuneGrid = rf.grid,
                trControl = ctrl1)
ggplot(rf.fit, highlight = TRUE)
```
The random forest model performed very well, with an accuracy of 97.99% and a kappa of 0.9514, indicating very good agreement between predicted and actual values. The confusion matrix shows that the model correctly classified 391 out of 399 observations. The sensitivity and specificity of the model were both very high (93.33% and 100% respectively), and the positive predictive value and negative predictive value were both very good (100% and 97.21% respectively). Overall, the model appears to be very accurate and reliable.

7. SVM
```{r}
set.seed(1)
linear.tune <- tune.svm(binary_recovery ~ . ,
                data = dat[rowTrain,],
                kernel = "linear",
                cost = exp(seq(-5,2,len=50)),
                scale = TRUE)
plot(linear.tune)
linear.tune$best.parameters
best.linear <- linear.tune$best.model
summary(best.linear)

pred.linear <- predict(best.linear, newdata = dat[-rowTrain,])
confusionMatrix(data = pred.linear,
                reference = dat$binary_recovery[-rowTrain])



```

The SVM model achieved an accuracy of 0.9799, with a Kappa value of 0.9514. The model correctly classified 112 out of 120 non-recovery instances and 279 out of 279 recovery instances. The model performed better than the baseline No Information Rate of 0.6992, indicating that it was able to effectively separate the two classes.


```{r}
library(ggplot2)

# Parameter Tuning Plot
linear_tune <- tune.svm(binary_recovery ~ .,
                        data = dat[rowTrain, ],
                        kernel = "linear",
                        cost = exp(seq(-5, 2, len = 50)),
                        scale = TRUE)
linear_tune$results$cost <- exp(seq(-5, 2, len = 50))
linear_tune_df <- do.call(rbind, linear_tune$results)  # Convert list to data frame

linear_tune_plot <- ggplot(linear_tune_df, aes(x = log(cost), y = Accuracy)) +
  geom_line() +
  labs(x = "log(Cost)", y = "Accuracy") +
  ggtitle("Linear SVM Parameter Tuning") +
  theme_minimal()

print(linear_tune_plot)


# Variable Importance Plot
bagging <- randomForest(binary_recovery ~ .,
                       data = dat[rowTrain, ],
                       mtry = 8)

bagging_importance <- importance(bagging)
bagging_importance_plot <- ggplot(bagging_importance, aes(x = Importance, y = reorder(Variable, Importance))) +
  geom_point(size = 3) +
  labs(x = "Variable Importance", y = "Variable") +
  ggtitle("Random Forest (Bagging) Variable Importance") +
  theme_minimal()

print(bagging_importance_plot)



```
